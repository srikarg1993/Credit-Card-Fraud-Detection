{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has a wide variety of modeling algorithms for a binary classification problem. It reads a file creatd from a feaature selection process that has a reasonably small number of good variables. We can explore # ionput variables, model algorithms and tune model hyperparameters. ASt the end we can select our favorite algorithm, run it again and build the final model performace score percentile tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96397, 22)\n",
      "CPU times: user 180 ms, sys: 8.51 ms, total: 188 ms\n",
      "Wall time: 504 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>...</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "      <th>Card_Merchdesc_total_60</th>\n",
       "      <th>Merchnum_desc_max_7</th>\n",
       "      <th>merch_zip_total_0</th>\n",
       "      <th>zip3_actual/avg_60</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>10.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>10.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_zip3_total_7  Merchnum_max_7  card_zip_total_14  card_zip_total_60  \\\n",
       "0               3.62            3.62               3.62               3.62   \n",
       "1              31.42           31.42              31.42              31.42   \n",
       "2             178.49          178.49             178.49             178.49   \n",
       "3               3.62            3.62               3.62               3.62   \n",
       "4               7.24            3.62               7.24               7.24   \n",
       "\n",
       "   merch_zip_max_7  Card_Merchnum_desc_total_60  zip3_total_0  \\\n",
       "0             3.62                         3.62          3.62   \n",
       "1            31.42                        31.42         31.42   \n",
       "2           178.49                       178.49        178.49   \n",
       "3             3.62                         3.62          7.24   \n",
       "4             3.62                         7.24         10.86   \n",
       "\n",
       "   card_merch_total_30  card_zip_total_30  card_merch_total_60  ...  \\\n",
       "0                 3.62               3.62                 3.62  ...   \n",
       "1                31.42              31.42                31.42  ...   \n",
       "2               178.49             178.49               178.49  ...   \n",
       "3                 3.62               3.62                 3.62  ...   \n",
       "4                 7.24               7.24                 7.24  ...   \n",
       "\n",
       "   amount_cat  Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \\\n",
       "0           1                    3.62                         3.62   \n",
       "1           2                   31.42                        31.42   \n",
       "2           3                  178.49                       178.49   \n",
       "3           1                    3.62                         3.62   \n",
       "4           1                    7.24                         7.24   \n",
       "\n",
       "   Card_Merchdesc_total_60  Merchnum_desc_max_7  merch_zip_total_0  \\\n",
       "0                     3.62                 3.62               3.62   \n",
       "1                    31.42                31.42              31.42   \n",
       "2                   178.49               178.49             178.49   \n",
       "3                     3.62                 3.62               7.24   \n",
       "4                     7.24                 3.62              10.86   \n",
       "\n",
       "   zip3_actual/avg_60  Card_Merchdesc_total_7  Recnum  Fraud  \n",
       "0                 1.0                    3.62       1      0  \n",
       "1                 1.0                   31.42       2      0  \n",
       "2                 1.0                  178.49       3      0  \n",
       "3                 1.0                    3.62       4      0  \n",
       "4                 1.0                    7.24       5      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars = pd.read_csv('vars_final 20 OK.csv')\n",
    "print(vars.shape)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card_zip3_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merchnum_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>card_zip_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card_zip_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>merch_zip_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Card_Merchnum_desc_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zip3_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>card_merch_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>card_zip_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>card_merch_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Merchnum_desc_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Merchnum_desc_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amount_cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merchnum_desc_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Card_Merchnum_desc_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Card_Merchdesc_total_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Merchnum_desc_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>merch_zip_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zip3_actual/avg_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Card_Merchdesc_total_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable name\n",
       "0             card_zip3_total_7\n",
       "1                Merchnum_max_7\n",
       "2             card_zip_total_14\n",
       "3             card_zip_total_60\n",
       "4               merch_zip_max_7\n",
       "5   Card_Merchnum_desc_total_60\n",
       "6                  zip3_total_0\n",
       "7           card_merch_total_30\n",
       "8             card_zip_total_30\n",
       "9           card_merch_total_60\n",
       "10        Merchnum_desc_total_7\n",
       "11          Merchnum_desc_avg_7\n",
       "12                   amount_cat\n",
       "13       Merchnum_desc_total_14\n",
       "14  Card_Merchnum_desc_total_30\n",
       "15      Card_Merchdesc_total_60\n",
       "16          Merchnum_desc_max_7\n",
       "17            merch_zip_total_0\n",
       "18           zip3_actual/avg_60\n",
       "19       Card_Merchdesc_total_7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vars = pd.read_csv('final_vars_list 20 OK.csv')\n",
    "final_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'card_zip3_total_7',\n",
       " 'Merchnum_max_7',\n",
       " 'card_zip_total_14',\n",
       " 'card_zip_total_60',\n",
       " 'merch_zip_max_7',\n",
       " 'Card_Merchnum_desc_total_60',\n",
       " 'zip3_total_0',\n",
       " 'card_merch_total_30',\n",
       " 'card_zip_total_30',\n",
       " 'card_merch_total_60',\n",
       " 'Merchnum_desc_total_7',\n",
       " 'Merchnum_desc_avg_7',\n",
       " 'amount_cat',\n",
       " 'Merchnum_desc_total_14',\n",
       " 'Card_Merchnum_desc_total_30']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.rename(columns={'recnum':'Recnum'},inplace=True)\n",
    "numvars = min(15,len(final_vars))\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(final_vars.iloc[i]['variable name'])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>10.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "0       1      0               3.62            3.62               3.62   \n",
       "1       2      0              31.42           31.42              31.42   \n",
       "2       3      0             178.49          178.49             178.49   \n",
       "3       4      0               3.62            3.62               3.62   \n",
       "4       5      0               7.24            3.62               7.24   \n",
       "\n",
       "   card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "0               3.62             3.62                         3.62   \n",
       "1              31.42            31.42                        31.42   \n",
       "2             178.49           178.49                       178.49   \n",
       "3               3.62             3.62                         3.62   \n",
       "4               7.24             3.62                         7.24   \n",
       "\n",
       "   zip3_total_0  card_merch_total_30  card_zip_total_30  card_merch_total_60  \\\n",
       "0          3.62                 3.62               3.62                 3.62   \n",
       "1         31.42                31.42              31.42                31.42   \n",
       "2        178.49               178.49             178.49               178.49   \n",
       "3          7.24                 3.62               3.62                 3.62   \n",
       "4         10.86                 7.24               7.24                 7.24   \n",
       "\n",
       "   Merchnum_desc_total_7  Merchnum_desc_avg_7  amount_cat  \\\n",
       "0                   3.62                 3.62           1   \n",
       "1                  31.42                31.42           2   \n",
       "2                 178.49               178.49           3   \n",
       "3                   3.62                 3.62           1   \n",
       "4                   7.24                 3.62           1   \n",
       "\n",
       "   Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "0                    3.62                         3.62  \n",
       "1                   31.42                        31.42  \n",
       "2                  178.49                       178.49  \n",
       "3                    3.62                         3.62  \n",
       "4                    7.24                         7.24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = vars.filter(final_vars_list,axis=1)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96397, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars.rename(columns={'fraud_label':'Fraud'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>10.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>14.53</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.62</td>\n",
       "      <td>18.15</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>4</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>2</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.67</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.67</td>\n",
       "      <td>10.86</td>\n",
       "      <td>21.77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "0       1      0               3.62            3.62               3.62   \n",
       "1       2      0              31.42           31.42              31.42   \n",
       "2       3      0             178.49          178.49             178.49   \n",
       "3       4      0               3.62            3.62               3.62   \n",
       "4       5      0               7.24            3.62               7.24   \n",
       "5       6      0               3.67            3.67               3.67   \n",
       "6       7      0               3.62            3.67               3.62   \n",
       "7       8      0             230.32          230.32             230.32   \n",
       "8       9      0              62.11           62.11              62.11   \n",
       "9      10      0              10.86            3.67              10.86   \n",
       "\n",
       "   card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "0               3.62             3.62                         3.62   \n",
       "1              31.42            31.42                        31.42   \n",
       "2             178.49           178.49                       178.49   \n",
       "3               3.62             3.62                         3.62   \n",
       "4               7.24             3.62                         7.24   \n",
       "5               3.67             3.67                         3.67   \n",
       "6               3.62             3.67                         3.62   \n",
       "7             230.32           230.32                       230.32   \n",
       "8              62.11            62.11                        62.11   \n",
       "9              10.86             3.67                        10.86   \n",
       "\n",
       "   zip3_total_0  card_merch_total_30  card_zip_total_30  card_merch_total_60  \\\n",
       "0          3.62                 3.62               3.62                 3.62   \n",
       "1         31.42                31.42              31.42                31.42   \n",
       "2        178.49               178.49             178.49               178.49   \n",
       "3          7.24                 3.62               3.62                 3.62   \n",
       "4         10.86                 7.24               7.24                 7.24   \n",
       "5         14.53                 3.67               3.67                 3.67   \n",
       "6         18.15                 3.62               3.62                 3.62   \n",
       "7        230.32               230.32             230.32               230.32   \n",
       "8         62.11                62.11              62.11                62.11   \n",
       "9         21.77                10.86              10.86                10.86   \n",
       "\n",
       "   Merchnum_desc_total_7  Merchnum_desc_avg_7  amount_cat  \\\n",
       "0                   3.62                 3.62           1   \n",
       "1                  31.42                31.42           2   \n",
       "2                 178.49               178.49           3   \n",
       "3                   3.62                 3.62           1   \n",
       "4                   7.24                 3.62           1   \n",
       "5                   3.67                 3.67           1   \n",
       "6                   7.24                 3.62           1   \n",
       "7                 230.32               230.32           4   \n",
       "8                  62.11                62.11           2   \n",
       "9                  10.86                 3.62           1   \n",
       "\n",
       "   Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "0                    3.62                         3.62  \n",
       "1                   31.42                        31.42  \n",
       "2                  178.49                       178.49  \n",
       "3                    3.62                         3.62  \n",
       "4                    7.24                         7.24  \n",
       "5                    3.67                         3.67  \n",
       "6                    7.24                         3.62  \n",
       "7                  230.32                       230.32  \n",
       "8                   62.11                        62.11  \n",
       "9                   10.86                        10.86  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96397, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.0000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48365.481820</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>766.708755</td>\n",
       "      <td>811.760529</td>\n",
       "      <td>806.656625</td>\n",
       "      <td>1266.636330</td>\n",
       "      <td>810.781862</td>\n",
       "      <td>1086.172428</td>\n",
       "      <td>1385.252825</td>\n",
       "      <td>922.819733</td>\n",
       "      <td>992.1012</td>\n",
       "      <td>1141.217228</td>\n",
       "      <td>2254.087053</td>\n",
       "      <td>396.376864</td>\n",
       "      <td>2.999222</td>\n",
       "      <td>3629.081765</td>\n",
       "      <td>886.797254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27945.003883</td>\n",
       "      <td>0.104236</td>\n",
       "      <td>4137.374620</td>\n",
       "      <td>1342.561234</td>\n",
       "      <td>4186.923501</td>\n",
       "      <td>4651.346596</td>\n",
       "      <td>1342.127110</td>\n",
       "      <td>4546.365935</td>\n",
       "      <td>3305.170073</td>\n",
       "      <td>4298.907440</td>\n",
       "      <td>4346.6019</td>\n",
       "      <td>4551.733037</td>\n",
       "      <td>6299.460682</td>\n",
       "      <td>697.750999</td>\n",
       "      <td>1.414452</td>\n",
       "      <td>8698.384382</td>\n",
       "      <td>4291.154066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.150000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>132.530000</td>\n",
       "      <td>124.880000</td>\n",
       "      <td>68.820000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>93.790000</td>\n",
       "      <td>105.7500</td>\n",
       "      <td>108.810000</td>\n",
       "      <td>130.350000</td>\n",
       "      <td>55.970000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.900000</td>\n",
       "      <td>61.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>238.200000</td>\n",
       "      <td>389.970000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>277.670000</td>\n",
       "      <td>545.750000</td>\n",
       "      <td>289.680000</td>\n",
       "      <td>322.7800</td>\n",
       "      <td>348.790000</td>\n",
       "      <td>502.820000</td>\n",
       "      <td>205.450000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>699.940000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72578.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>693.560000</td>\n",
       "      <td>1131.400000</td>\n",
       "      <td>718.640000</td>\n",
       "      <td>1178.840000</td>\n",
       "      <td>1128.960000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1630.710000</td>\n",
       "      <td>824.680000</td>\n",
       "      <td>906.2700</td>\n",
       "      <td>1023.040000</td>\n",
       "      <td>2137.500000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3267.950000</td>\n",
       "      <td>780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96753.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.4100</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>313984.550000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>319334.680000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Recnum         Fraud  card_zip3_total_7  Merchnum_max_7  \\\n",
       "count  96397.000000  96397.000000       96397.000000    96397.000000   \n",
       "mean   48365.481820      0.010986         766.708755      811.760529   \n",
       "std    27945.003883      0.104236        4137.374620     1342.561234   \n",
       "min        1.000000      0.000000           0.010000        0.010000   \n",
       "25%    24154.000000      0.000000          77.150000      125.000000   \n",
       "50%    48365.000000      0.000000         238.200000      389.970000   \n",
       "75%    72578.000000      0.000000         693.560000     1131.400000   \n",
       "max    96753.000000      1.000000      306633.410000    47900.000000   \n",
       "\n",
       "       card_zip_total_14  card_zip_total_60  merch_zip_max_7  \\\n",
       "count       96397.000000       96397.000000     96397.000000   \n",
       "mean          806.656625        1266.636330       810.781862   \n",
       "std          4186.923501        4651.346596      1342.127110   \n",
       "min             0.010000           0.010000         0.010000   \n",
       "25%            85.000000         132.530000       124.880000   \n",
       "50%           257.000000         410.000000       389.000000   \n",
       "75%           718.640000        1178.840000      1128.960000   \n",
       "max        306633.410000      306633.410000     47900.000000   \n",
       "\n",
       "       Card_Merchnum_desc_total_60   zip3_total_0  card_merch_total_30  \\\n",
       "count                 96397.000000   96397.000000         96397.000000   \n",
       "mean                   1086.172428    1385.252825           922.819733   \n",
       "std                    4546.365935    3305.170073          4298.907440   \n",
       "min                       0.010000       0.010000             0.010000   \n",
       "25%                      68.820000     169.000000            93.790000   \n",
       "50%                     277.670000     545.750000           289.680000   \n",
       "75%                     933.000000    1630.710000           824.680000   \n",
       "max                  306633.410000  217467.180000        306633.410000   \n",
       "\n",
       "       card_zip_total_30  card_merch_total_60  Merchnum_desc_total_7  \\\n",
       "count         96397.0000         96397.000000           96397.000000   \n",
       "mean            992.1012          1141.217228            2254.087053   \n",
       "std            4346.6019          4551.733037            6299.460682   \n",
       "min               0.0100             0.010000               0.010000   \n",
       "25%             105.7500           108.810000             130.350000   \n",
       "50%             322.7800           348.790000             502.820000   \n",
       "75%             906.2700          1023.040000            2137.500000   \n",
       "max          306633.4100        306633.410000          313984.550000   \n",
       "\n",
       "       Merchnum_desc_avg_7    amount_cat  Merchnum_desc_total_14  \\\n",
       "count         96397.000000  96397.000000            96397.000000   \n",
       "mean            396.376864      2.999222             3629.081765   \n",
       "std             697.750999      1.414452             8698.384382   \n",
       "min               0.010000      1.000000                0.010000   \n",
       "25%              55.970000      2.000000              160.900000   \n",
       "50%             205.450000      3.000000              699.940000   \n",
       "75%             481.000000      4.000000             3267.950000   \n",
       "max           28392.840000      5.000000           319334.680000   \n",
       "\n",
       "       Card_Merchnum_desc_total_30  \n",
       "count                 96397.000000  \n",
       "mean                    886.797254  \n",
       "std                    4291.154066  \n",
       "min                       0.010000  \n",
       "25%                      61.940000  \n",
       "50%                     240.000000  \n",
       "75%                     780.000000  \n",
       "max                  306633.410000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.0000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>766.708755</td>\n",
       "      <td>811.760529</td>\n",
       "      <td>806.656625</td>\n",
       "      <td>1266.636330</td>\n",
       "      <td>810.781862</td>\n",
       "      <td>1086.172428</td>\n",
       "      <td>1385.252825</td>\n",
       "      <td>922.819733</td>\n",
       "      <td>992.1012</td>\n",
       "      <td>1141.217228</td>\n",
       "      <td>2254.087053</td>\n",
       "      <td>396.376864</td>\n",
       "      <td>2.999222</td>\n",
       "      <td>3629.081765</td>\n",
       "      <td>886.797254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4137.374620</td>\n",
       "      <td>1342.561234</td>\n",
       "      <td>4186.923501</td>\n",
       "      <td>4651.346596</td>\n",
       "      <td>1342.127110</td>\n",
       "      <td>4546.365935</td>\n",
       "      <td>3305.170073</td>\n",
       "      <td>4298.907440</td>\n",
       "      <td>4346.6019</td>\n",
       "      <td>4551.733037</td>\n",
       "      <td>6299.460682</td>\n",
       "      <td>697.750999</td>\n",
       "      <td>1.414452</td>\n",
       "      <td>8698.384382</td>\n",
       "      <td>4291.154066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.150000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>132.530000</td>\n",
       "      <td>124.880000</td>\n",
       "      <td>68.820000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>93.790000</td>\n",
       "      <td>105.7500</td>\n",
       "      <td>108.810000</td>\n",
       "      <td>130.350000</td>\n",
       "      <td>55.970000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.900000</td>\n",
       "      <td>61.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>238.200000</td>\n",
       "      <td>389.970000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>277.670000</td>\n",
       "      <td>545.750000</td>\n",
       "      <td>289.680000</td>\n",
       "      <td>322.7800</td>\n",
       "      <td>348.790000</td>\n",
       "      <td>502.820000</td>\n",
       "      <td>205.450000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>699.940000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>693.560000</td>\n",
       "      <td>1131.400000</td>\n",
       "      <td>718.640000</td>\n",
       "      <td>1178.840000</td>\n",
       "      <td>1128.960000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1630.710000</td>\n",
       "      <td>824.680000</td>\n",
       "      <td>906.2700</td>\n",
       "      <td>1023.040000</td>\n",
       "      <td>2137.500000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3267.950000</td>\n",
       "      <td>780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.4100</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>313984.550000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>319334.680000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "count       96397.000000    96397.000000       96397.000000   \n",
       "mean          766.708755      811.760529         806.656625   \n",
       "std          4137.374620     1342.561234        4186.923501   \n",
       "min             0.010000        0.010000           0.010000   \n",
       "25%            77.150000      125.000000          85.000000   \n",
       "50%           238.200000      389.970000         257.000000   \n",
       "75%           693.560000     1131.400000         718.640000   \n",
       "max        306633.410000    47900.000000      306633.410000   \n",
       "\n",
       "       card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "count       96397.000000     96397.000000                 96397.000000   \n",
       "mean         1266.636330       810.781862                  1086.172428   \n",
       "std          4651.346596      1342.127110                  4546.365935   \n",
       "min             0.010000         0.010000                     0.010000   \n",
       "25%           132.530000       124.880000                    68.820000   \n",
       "50%           410.000000       389.000000                   277.670000   \n",
       "75%          1178.840000      1128.960000                   933.000000   \n",
       "max        306633.410000     47900.000000                306633.410000   \n",
       "\n",
       "        zip3_total_0  card_merch_total_30  card_zip_total_30  \\\n",
       "count   96397.000000         96397.000000         96397.0000   \n",
       "mean     1385.252825           922.819733           992.1012   \n",
       "std      3305.170073          4298.907440          4346.6019   \n",
       "min         0.010000             0.010000             0.0100   \n",
       "25%       169.000000            93.790000           105.7500   \n",
       "50%       545.750000           289.680000           322.7800   \n",
       "75%      1630.710000           824.680000           906.2700   \n",
       "max    217467.180000        306633.410000        306633.4100   \n",
       "\n",
       "       card_merch_total_60  Merchnum_desc_total_7  Merchnum_desc_avg_7  \\\n",
       "count         96397.000000           96397.000000         96397.000000   \n",
       "mean           1141.217228            2254.087053           396.376864   \n",
       "std            4551.733037            6299.460682           697.750999   \n",
       "min               0.010000               0.010000             0.010000   \n",
       "25%             108.810000             130.350000            55.970000   \n",
       "50%             348.790000             502.820000           205.450000   \n",
       "75%            1023.040000            2137.500000           481.000000   \n",
       "max          306633.410000          313984.550000         28392.840000   \n",
       "\n",
       "         amount_cat  Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "count  96397.000000            96397.000000                 96397.000000  \n",
       "mean       2.999222             3629.081765                   886.797254  \n",
       "std        1.414452             8698.384382                  4291.154066  \n",
       "min        1.000000                0.010000                     0.010000  \n",
       "25%        2.000000              160.900000                    61.940000  \n",
       "50%        3.000000              699.940000                   240.000000  \n",
       "75%        4.000000             3267.950000                   780.000000  \n",
       "max        5.000000           319334.680000                306633.410000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>Merchnum_max_7</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_zip_total_60</th>\n",
       "      <th>merch_zip_max_7</th>\n",
       "      <th>Card_Merchnum_desc_total_60</th>\n",
       "      <th>zip3_total_0</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_merch_total_60</th>\n",
       "      <th>Merchnum_desc_total_7</th>\n",
       "      <th>Merchnum_desc_avg_7</th>\n",
       "      <th>amount_cat</th>\n",
       "      <th>Merchnum_desc_total_14</th>\n",
       "      <th>Card_Merchnum_desc_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.012382</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>-0.012245</td>\n",
       "      <td>-0.010559</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>-0.010953</td>\n",
       "      <td>-0.009276</td>\n",
       "      <td>-0.011740</td>\n",
       "      <td>-0.011516</td>\n",
       "      <td>-0.010922</td>\n",
       "      <td>-0.009980</td>\n",
       "      <td>-0.007535</td>\n",
       "      <td>-7.842749e-17</td>\n",
       "      <td>-0.007894</td>\n",
       "      <td>-0.011781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477940</td>\n",
       "      <td>0.851103</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.631814</td>\n",
       "      <td>0.850917</td>\n",
       "      <td>0.606050</td>\n",
       "      <td>0.716087</td>\n",
       "      <td>0.537816</td>\n",
       "      <td>0.554095</td>\n",
       "      <td>0.607794</td>\n",
       "      <td>0.714933</td>\n",
       "      <td>0.848842</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.823226</td>\n",
       "      <td>0.534859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.185310</td>\n",
       "      <td>-0.604628</td>\n",
       "      <td>-0.192659</td>\n",
       "      <td>-0.272314</td>\n",
       "      <td>-0.604095</td>\n",
       "      <td>-0.238908</td>\n",
       "      <td>-0.419114</td>\n",
       "      <td>-0.214661</td>\n",
       "      <td>-0.228245</td>\n",
       "      <td>-0.250719</td>\n",
       "      <td>-0.357821</td>\n",
       "      <td>-0.568063</td>\n",
       "      <td>-1.413425e+00</td>\n",
       "      <td>-0.417212</td>\n",
       "      <td>-0.206655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.166666</td>\n",
       "      <td>-0.511530</td>\n",
       "      <td>-0.172360</td>\n",
       "      <td>-0.243823</td>\n",
       "      <td>-0.511056</td>\n",
       "      <td>-0.223773</td>\n",
       "      <td>-0.367985</td>\n",
       "      <td>-0.192847</td>\n",
       "      <td>-0.203918</td>\n",
       "      <td>-0.226816</td>\n",
       "      <td>-0.337130</td>\n",
       "      <td>-0.487863</td>\n",
       "      <td>-7.064377e-01</td>\n",
       "      <td>-0.398716</td>\n",
       "      <td>-0.192223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.127740</td>\n",
       "      <td>-0.314169</td>\n",
       "      <td>-0.131279</td>\n",
       "      <td>-0.184170</td>\n",
       "      <td>-0.314264</td>\n",
       "      <td>-0.177835</td>\n",
       "      <td>-0.253997</td>\n",
       "      <td>-0.147279</td>\n",
       "      <td>-0.153987</td>\n",
       "      <td>-0.174094</td>\n",
       "      <td>-0.278003</td>\n",
       "      <td>-0.273632</td>\n",
       "      <td>5.500594e-04</td>\n",
       "      <td>-0.336745</td>\n",
       "      <td>-0.150728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.017680</td>\n",
       "      <td>0.238082</td>\n",
       "      <td>-0.021022</td>\n",
       "      <td>-0.018875</td>\n",
       "      <td>0.237070</td>\n",
       "      <td>-0.033691</td>\n",
       "      <td>0.074265</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.019747</td>\n",
       "      <td>-0.025963</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>0.121280</td>\n",
       "      <td>7.075378e-01</td>\n",
       "      <td>-0.041517</td>\n",
       "      <td>-0.024888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.414525e+00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  Merchnum_max_7  card_zip_total_14  \\\n",
       "count       96397.000000    96397.000000       96397.000000   \n",
       "mean           -0.012382       -0.009205          -0.012245   \n",
       "std             0.477940        0.851103           0.496200   \n",
       "min            -0.185310       -0.604628          -0.192659   \n",
       "25%            -0.166666       -0.511530          -0.172360   \n",
       "50%            -0.127740       -0.314169          -0.131279   \n",
       "75%            -0.017680        0.238082          -0.021022   \n",
       "max            10.000000       10.000000          10.000000   \n",
       "\n",
       "       card_zip_total_60  merch_zip_max_7  Card_Merchnum_desc_total_60  \\\n",
       "count       96397.000000     96397.000000                 96397.000000   \n",
       "mean           -0.010559        -0.009214                    -0.010953   \n",
       "std             0.631814         0.850917                     0.606050   \n",
       "min            -0.272314        -0.604095                    -0.238908   \n",
       "25%            -0.243823        -0.511056                    -0.223773   \n",
       "50%            -0.184170        -0.314264                    -0.177835   \n",
       "75%            -0.018875         0.237070                    -0.033691   \n",
       "max            10.000000        10.000000                    10.000000   \n",
       "\n",
       "       zip3_total_0  card_merch_total_30  card_zip_total_30  \\\n",
       "count  96397.000000         96397.000000       96397.000000   \n",
       "mean      -0.009276            -0.011740          -0.011516   \n",
       "std        0.716087             0.537816           0.554095   \n",
       "min       -0.419114            -0.214661          -0.228245   \n",
       "25%       -0.367985            -0.192847          -0.203918   \n",
       "50%       -0.253997            -0.147279          -0.153987   \n",
       "75%        0.074265            -0.022829          -0.019747   \n",
       "max       10.000000            10.000000          10.000000   \n",
       "\n",
       "       card_merch_total_60  Merchnum_desc_total_7  Merchnum_desc_avg_7  \\\n",
       "count         96397.000000           96397.000000         96397.000000   \n",
       "mean             -0.010922              -0.009980            -0.007535   \n",
       "std               0.607794               0.714933             0.848842   \n",
       "min              -0.250719              -0.357821            -0.568063   \n",
       "25%              -0.226816              -0.337130            -0.487863   \n",
       "50%              -0.174094              -0.278003            -0.273632   \n",
       "75%              -0.025963              -0.018507             0.121280   \n",
       "max              10.000000              10.000000            10.000000   \n",
       "\n",
       "         amount_cat  Merchnum_desc_total_14  Card_Merchnum_desc_total_30  \n",
       "count  9.639700e+04            96397.000000                 96397.000000  \n",
       "mean  -7.842749e-17               -0.007894                    -0.011781  \n",
       "std    1.000000e+00                0.823226                     0.534859  \n",
       "min   -1.413425e+00               -0.417212                    -0.206655  \n",
       "25%   -7.064377e-01               -0.398716                    -0.192223  \n",
       "50%    5.500594e-04               -0.336745                    -0.150728  \n",
       "75%    7.075378e-01               -0.041517                    -0.024888  \n",
       "max    1.414525e+00               10.000000                    10.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values\n",
    "cols = X.columns\n",
    "X.loc[:,cols] = X[cols].clip(upper=Clip)\n",
    "X.loc[:,cols] = X[cols].clip(lower=-1*Clip)\n",
    "# X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time\n",
    "oot_recnum=84300\n",
    "X_trntst = X[0:oot_recnum]\n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 0\n",
    "nitermax = 10\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve a linear regression with ridge and lass regularization and watch how the variable weights evolve with the regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(7,-2,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "coefs = []\n",
    "for a in alphas: \n",
    "    ridge.set_params(alpha=a) \n",
    "    ridge.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(ridge.coef_) \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ridge')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha') \n",
    "plt.ylabel('standadized coef') \n",
    "plt.title('Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(2,-8,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-26d9a7bd411e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_trn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcoefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print('Shape:',np.shape(coefs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mthis_Xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_iter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m                 self.path(X, y[:, k],\n\u001b[0m\u001b[1;32m    845\u001b[0m                           \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                           \u001b[0mn_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 tol, rng, random, positive)\n\u001b[1;32m    529\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             model = cd_fast.enet_coordinate_descent(\n\u001b[0m\u001b[1;32m    531\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 positive)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sometimes this cell takes a long time\n",
    "lasso = Lasso(max_iter=10000) \n",
    "coefs = [] \n",
    "for a in alphas: \n",
    "    lasso.set_params(alpha=a) \n",
    "    lasso.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(lasso.coef_) \n",
    "# print('Shape:',np.shape(coefs)\n",
    "print('Selected Features:', list(vars.columns[np.where(lasso.coef_!=0)[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (81, 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0c7701f6f456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get the current Axes instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (81, 15)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance \n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('standerdized coef') \n",
    "plt.title('Lasso')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can comment out any of these model cells and just explore one model type. You can also just rerun that single cell multiple times as you explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modeling_output = pd.DataFrame(columns=['Model','Trn','Tst','OOT'],index=range(1000))\n",
    "counter = 0\n",
    "model_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6623164763458401 0.6816479400749064 0.2569832402234637\n",
      "1 0.6876006441223832 0.6177606177606177 0.29608938547486036\n",
      "2 0.6672268907563025 0.6807017543859649 0.30726256983240224\n",
      "3 0.6834415584415584 0.6515151515151515 0.2905027932960894\n",
      "4 0.6677685950413224 0.6763636363636364 0.2905027932960894\n",
      "5 0.6939799331103679 0.6063829787234043 0.2849162011173184\n",
      "6 0.6492890995260664 0.6842105263157895 0.2737430167597765\n",
      "7 0.6493288590604027 0.7183098591549296 0.2905027932960894\n",
      "8 0.6644844517184942 0.6728624535315985 0.2905027932960894\n",
      "9 0.6978297161936561 0.6192170818505338 0.3016759776536313\n",
      "trn    0.672327\n",
      "tst    0.660897\n",
      "oot    0.288268\n",
      "dtype: float64\n",
      "CPU times: user 8.77 s, sys: 22.7 s, total: 31.5 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['log reg',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=8,min_samples_split=100,min_samples_leaf=60)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['DT',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "\n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# RF\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=40,max_depth=7,min_samples_split=100,min_samples_leaf=60,max_features=8)\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['RF',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = lgb.LGBMClassifier(num_leaves=3,n_estimators=600)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# NN\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(10,10),alpha=.005,solver='adam',activation='relu',\n",
    "                          max_iter=1000,learning_rate='adaptive',learning_rate_init=.01)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['NN',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# GBC\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = GradientBoostingClassifier(learning_rate=0.01,max_depth=4,n_estimators=300)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['GBC',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = CatBoostClassifier(verbose=0,\n",
    "            iterations=100,\n",
    "#             learning_rate=0.03,\n",
    "#             l2_leaf_reg=5\n",
    "    \n",
    "    )\n",
    "#\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['cat boost',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # XGB\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = XGBClassifier(\n",
    "#         booster='gbtree',\n",
    "#         max_depth=5, \n",
    "#         min_child_weight=75,\n",
    "#         sub_sample=75,\n",
    "#         gamma=0.01, \n",
    "#     )\n",
    "\n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['XGB',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Knn\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=300) \n",
    "    \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['Knn',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # SVM\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = svm.SVC(\n",
    "#         C=.1, \n",
    "# #         gamma=100,\n",
    "# #         kernel='linear',\n",
    "#         kernel='poly',\n",
    "#         probability=True)\n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['SVM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Modeling_output.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpivot = df.melt( id_vars='Model', value_vars=['Trn','Tst','OOT'], var_name=['Type'], value_name='Value')\n",
    "df_unpivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = df_unpivot[(df_unpivot['Type']=='Trn') | (df_unpivot['Type']=='Tst') | (df_unpivot['Type']=='OOT')]\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df.groupby('Model').agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# plt.rcParams.update({'font.size':20})\n",
    "# ax = sns.boxplot(x='Model',y='Trn', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('Train Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='Tst', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('Test Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='OOT', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('OOT Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='OOT', data=df, color='navy')\n",
    "ax = sns.boxplot(x='Model',y='Value',hue='Type', data=df_compare, palette=['navy','r','g'])\n",
    "# Select which box you want to change    \n",
    "mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# Change the appearance of that box\n",
    "mybox.set_edgecolor('black')\n",
    "# mybox.set_linewidth(3)\n",
    "# plxlabelabel('')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel('Score (FDR3%)')\n",
    "plt.yticks(np.arange(0,1,.1))\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('modeling.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook makes the tables for your final model of choice. You need to run that final model only once (no CV). If you want you can run the below cell over and over by itself until it gives you a model you like. But you can't change from your best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for niter in range(30):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "# here's where you put your final model of choice\n",
    "    model = lgb.LGBMClassifier(num_leaves=3,n_estimators=50)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    if(FDR3.loc[niter, 'oot'] > .56): break\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = X_trn.copy()\n",
    "X_tst_eval = X_tst.copy()\n",
    "X_oot_eval = X_oot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "bad_tot_trn = sum(X_trn_eval.loc[:, 'Fraud'])\n",
    "bad_tot_tst = sum(X_tst_eval.loc[:, 'Fraud'])\n",
    "bad_tot_oot = sum(X_oot_eval.loc[:, 'Fraud'])\n",
    "num_tot_trn = len(X_trn_eval)\n",
    "num_tot_tst = len(X_tst_eval)\n",
    "num_tot_oot = len(X_oot_eval)\n",
    "good_tot_trn = num_tot_trn - bad_tot_trn\n",
    "good_tot_tst = num_tot_tst - bad_tot_tst\n",
    "good_tot_oot = num_tot_oot - bad_tot_oot\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(101):\n",
    "    percent_rows_trn = int(round(X_trn_eval.shape[0]*0.01*i))\n",
    "    percent_rows_tst = int(round(X_tst_eval.shape[0]*0.01*i))\n",
    "    percent_rows_oot = int(round(X_oot_eval.shape[0]*0.01*i))\n",
    "    temp_trn = trn_sorted.head(percent_rows_trn)\n",
    "    temp_tst = tst_sorted.head(percent_rows_tst)\n",
    "    temp_oot = oot_sorted.head(percent_rows_oot)\n",
    "    num_bad_trn = sum(temp_trn.loc[:,'Fraud'])\n",
    "    num_bad_tst = sum(temp_tst.loc[:,'Fraud'])\n",
    "    num_bad_oot = sum(temp_oot.loc[:,'Fraud'])\n",
    "    num_tot_trn = len(temp_trn)\n",
    "    num_tot_tst = len(temp_tst)\n",
    "    num_tot_oot = len(temp_oot)\n",
    "    num_good_trn = num_tot_trn - num_bad_trn\n",
    "    num_good_tst = num_tot_tst - num_bad_tst\n",
    "    num_good_oot = num_tot_oot - num_bad_oot\n",
    "    \n",
    "    FDR_trn.loc[i, 'bin'] = i\n",
    "    FDR_trn.loc[i,'#recs'] = 0\n",
    "    FDR_trn.loc[i, 'tot'] = num_tot_trn\n",
    "    FDR_trn.loc[i, 'cg'] = num_good_trn\n",
    "    FDR_trn.loc[i, 'cb'] = num_bad_trn\n",
    "    FDR_tst.loc[i, 'bin'] = i\n",
    "    FDR_tst.loc[i, 'tot'] = num_tot_tst\n",
    "    FDR_tst.loc[i, 'cg'] = num_good_tst\n",
    "    FDR_tst.loc[i, 'cb'] = num_bad_tst\n",
    "    FDR_oot.loc[i, 'bin'] = i\n",
    "    FDR_oot.loc[i, 'tot'] = num_tot_oot\n",
    "    FDR_oot.loc[i, 'cg'] = num_good_oot\n",
    "    FDR_oot.loc[i, 'cb'] = num_bad_oot\n",
    "    if i != 0:\n",
    "        FDR_trn.loc[i, '#g'] = num_good_trn - FDR_trn.loc[i-1, 'cg']\n",
    "        FDR_trn.loc[i, '#b'] = num_bad_trn - FDR_trn.loc[i-1, 'cb']\n",
    "        FDR_trn.loc[i,'#recs'] = FDR_trn.loc[i, '#g'] + FDR_trn.loc[i, '#b']\n",
    "        FDR_trn.loc[i, '%g'] = 100* (num_good_trn - FDR_trn.loc[i-1, 'cg']) / (num_tot_trn - FDR_trn.loc[i-1, 'tot'])\n",
    "        FDR_trn.loc[i, '%b'] = 100 - FDR_trn.loc[i, '%g']\n",
    "        FDR_trn.loc[i, '%cg'] = 100 * num_good_trn / good_tot_trn\n",
    "        FDR_trn.loc[i, 'FDR'] = 100 * num_bad_trn / bad_tot_trn\n",
    "        FDR_trn.loc[i, 'KS'] = FDR_trn.loc[i, 'FDR'] - FDR_trn.loc[i, '%cg']\n",
    "        FDR_trn.loc[i, 'FPR'] = num_good_trn / num_bad_trn\n",
    "        FDR_tst.loc[i, '#g'] = num_good_tst - FDR_tst.loc[i-1, 'cg']\n",
    "        FDR_tst.loc[i, '#b'] = num_bad_tst - FDR_tst.loc[i-1, 'cb']\n",
    "        FDR_tst.loc[i,'#recs'] = FDR_tst.loc[i, '#g'] + FDR_tst.loc[i, '#b']\n",
    "        FDR_tst.loc[i, '%g'] = 100* (num_good_tst - FDR_tst.loc[i-1, 'cg']) / (num_tot_tst - FDR_tst.loc[i-1, 'tot'])\n",
    "        FDR_tst.loc[i, '%b'] = 100 - FDR_tst.loc[i, '%g']\n",
    "        FDR_tst.loc[i, '%cg'] = 100 * num_good_tst / good_tot_tst\n",
    "        FDR_tst.loc[i, 'FDR'] = 100 * num_bad_tst / bad_tot_tst\n",
    "        FDR_tst.loc[i, 'KS'] = FDR_tst.loc[i, 'FDR'] - FDR_tst.loc[i, '%cg']\n",
    "        FDR_tst.loc[i, 'FPR'] = num_good_tst / num_bad_tst\n",
    "        FDR_oot.loc[i, '#g'] = num_good_oot - FDR_oot.loc[i-1, 'cg']\n",
    "        FDR_oot.loc[i, '#b'] = num_bad_oot - FDR_oot.loc[i-1, 'cb']\n",
    "        FDR_oot.loc[i,'#recs'] = FDR_oot.loc[i, '#g'] + FDR_oot.loc[i, '#b']\n",
    "        FDR_oot.loc[i, '%g'] = 100* (num_good_oot - FDR_oot.loc[i-1, 'cg']) / (num_tot_oot - FDR_oot.loc[i-1, 'tot'])\n",
    "        FDR_oot.loc[i, '%b'] = 100 - FDR_oot.loc[i, '%g']\n",
    "        FDR_oot.loc[i, '%cg'] = 100 * num_good_oot / good_tot_oot\n",
    "        FDR_oot.loc[i, 'FDR'] = 100 * num_bad_oot / bad_tot_oot\n",
    "        FDR_oot.loc[i, 'KS'] = FDR_oot.loc[i, 'FDR'] - FDR_oot.loc[i, '%cg']\n",
    "        FDR_oot.loc[i, 'FPR'] = num_good_oot / num_bad_oot\n",
    "\n",
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR3.to_csv('FDR3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
